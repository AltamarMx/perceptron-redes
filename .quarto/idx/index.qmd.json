{"title":"Del perceptrón a las redes neuronales","markdown":{"yaml":{"title":"Del perceptrón a las redes neuronales","author":"Guillermo Barrios","date":"2025-05-24","format":{"revealjs":{"theme":"simple","logo":"img/logo.png","slide-level":2,"slide-number":true,"incremental":true,"transition":"fade"}}},"headingText":"Del Perceptrón a las redes neuronales","headingAttr":{"id":"","classes":["center"],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n::: incremental \n_live coding_ en Google Colab para entender las redes neuronales.\n:::\n\n\n## Paper de Rosenblatt\n\n![](img/summary_perceptron.png){ .lightbox}\n\n\n\n## Detalle ampliado\n\n![](img/language_translation.png){ .lightbox }\n\n## Invierno de la IA (1974--1980)\n\n\n<br>\n<br>\n\n\n  El **informe Lighthill** de Sir James Lighthill (enero de 1973), encargado por el Consejo de Investigación de Ciencias del Reino Unido, concluyó que los avances reales de la IA estaban muy por debajo de lo prometido y recomendó retirar la mayor parte de los fondos estatales a proyectos en este campo.\n\n\n## ¿Qué es un perceptrón\n\n<br>\n\n- Unidad de procesamiento inspirada en la **neurona biológica**.  \n- Clasificador binario: decide si una entrada pertenece a una clase u otra.  \n- Propuesto por **Frank Rosenblatt** en 1957.\n\n\n## Esquema del perceptrón\n\n<br>\n<br>\n\n![](img/perceptron_scheme.png){ .lightbox}\n\n\n## Perceptrón\n\n<br>\n\n$z = \\mathbf{w}^\\top \\mathbf{x} + b$\n\n<br>\n\n$h(z) =\n\\begin{cases}\n0, & z < 0,\\\\\n1, & z \\ge 0,\n\\end{cases}$\n\n<br>\n\n$y = h\\bigl(\\mathbf{w}^\\top \\mathbf{x} + b\\bigr)$\n<!-- $y = f_{w,b}(\\mathbf{x}) = h\\bigl(\\mathbf{w}^\\top \\mathbf{x} + b\\bigr)$ -->\n\n<!-- ## Error y actualización -->\n\n$\\text{error}=Y−y$ \n\n$\\Delta w_i = \\mathrm{LR}\\,\\bigl(Y - y\\bigr)\\,x_i$\n\n\n\n## Manual de uso de un perceptrón\n\n\n1. **Inicializar**  \n   <!-- - Poner todos los pesos en cero.  \n   - Poner el sesgo (bias) en cero. -->\n\n2. **Iterar por épocas**  \n   <!-- - Repetir el ciclo de aprendizaje un número fijo de veces. -->\n\n3. **Para cada ejemplo de entrenamiento**  \n   1. **Calcular la salida del perceptrón**  \n      <!-- - Multiplicar las entradas por sus pesos, sumar el sesgo y aplicar la función de activación (paso unitario).   -->\n   2. **Calcular el error**  \n      <!-- - Restar la salida obtenida de la etiqueta correcta.   -->\n   3. **Actualizar los pesos y sesgo**  \n      <!-- - Ajustar cada peso proporcional al error, a la entrada correspondiente y a la tasa de aprendizaje.   -->\n   <!-- 4. **Actualizar el sesgo**   -->\n      <!-- - Ajustar el sesgo proporcional al error y a la tasa de aprendizaje. -->\n\n4. **Devolver pesos y el sesgo ajustados**\n\n## Puerta lógica AND\n\n\n:::: {.columns}\n\n:::{.column width=\"40%\" .right }\n\n<table>\n  <thead style=\"background-color: #f0f0f0;\">\n    <tr>\n      <th style=\"padding: 8px 12px; text-align: center;\">A</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">B</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">A & B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #d4edda; padding: 8px 12px; text-align: center;\">1</td>\n    </tr>\n  </tbody>\n</table>\n\n:::\n\n:::{.column width=\"60%\"}\n```python \n# Entradas\nx = np.array([\n    [0, 0],\n    [0, 1],\n    [1, 0],\n    [1, 1]\n])\n\n# Salidas deseadas\nY = np.array([0, 0, 0, 1])\n\n# Pesos iniciales\nw = np.array([0,0])\n\n# Sesgo inicial\nb = 0\n``` \n:::\n\n::::\n\n\n## Puerta lógica XOR\n\n:::: {.columns}\n\n:::{.column width=\"40%\" .right}\n\n<table>\n  <thead style=\"background-color: #f0f0f0;\">\n    <tr>\n      <th style=\"padding: 8px 12px; text-align: center;\">A</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">B</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">A ⊕ B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #d4edda; padding: 8px 12px; text-align: center;\">1</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #d4edda; padding: 8px 12px; text-align: center;\">1</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n  </tbody>\n</table>\n\n:::\n\n:::{.column width=\"60%\"}\n\n  ```python\n  # Entradas\n  x = np.array([\n      [0, 0],\n      [0, 1],\n      [1, 0],\n      [1, 1]\n  ])\n\n  # Salidas deseadas para XOR\n  Y = np.array([0, 1, 1, 0])\n\n# Pesos iniciales\nw = np.array([0,0])\n\n# Sesgo inicial\nb = 0\n```\n\n:::\n\n::::\n\n## AND: Perceptrón en Google Colab\n\n[![](img/google_colab_AND.png)](https://colab.research.google.com/drive/1OMee_vTQXbdsXTrN6syQydwA8k_ccVp_?usp=sharing)\n\n\n\n## XOR: Perceptrón en Google Colab\n\n[![](img/google_colab_XOR.png)](https://colab.research.google.com/drive/10nrTgGWWoMYsv_Os3cbFlF0eAI1Spx1p?usp=sharing)\n\n\n\n## AND y XOR\n\n![](img/error_XOR.png){.lightbox} \n\n## AND y XOR {.center}\n\n![](img/and_or_xor.png){.lightbox}\n\n\n## Backpropagation y Redes Neuronales\n\n| Año      | Investigador              | “Nombre” de la contribución   |\n| -------- | ------------------------- | ---------------------------   |\n| **1970** | Seppo Linnainmaa          | *Reverse-mode AD*             |\n| **1974** | Paul Werbos               | *Back-prop en redes*          |\n| **1982** | John Hopfield             | *Interés en redes neuronales* |\n| **1986** | Rumelhart-Hinton-Williams | *Back-prop popularizado*      |\n\n\n## Backpropagation + Multicapa\n\n| Paso               | Perceptrón simple            | Multicapa (+ back-prop)                     |\n| ------------------ | ---------------------------- | ------------------------------------------- |\n| Activación         | Escalón (`h`) – no derivable | Sigmoide – derivable                        |\n| Capas              | 1 (entrada → salida)         | 2 (entrada → oculta → salida)               |\n| Aprendizaje        | Regla de perceptrón          | Gradiente descendente con retro-propagación |\n| Puede aprender XOR | ❌                            | ✅                                           |\n\n## Multicapas {.center}\n\n![](img/multicapas.png)\n\n## Back-propagation: cómo aprende una red\n\n\n* Calcula el **error** en la salida.\n* Propaga ese error **hacia atrás** usando la regla de la cadena para obtener la pendiente (gradiente) de cada peso.\n* Combina los gradientes con **descenso del gradiente** (u otro optimizador) para actualizar los parámetros.\n* Permite entrenar cualquier grafo computacional compuesto de operaciones derivables.\n\n\n\n\n## XOR: Red neuronal en Google Colab\n\n[![](img/red_xor.png)](https://colab.research.google.com/drive/11L2vVBkQ65aNBMT-lrMGZjp5Q9606Nn9?usp=sharing)\n\n\n\n## Playground TensorFlow {.center}\n\n![https://playground.tensorflow.org/](https://playground.tensorflow.org/)\n","srcMarkdownNoYaml":"\n\n\n## Del Perceptrón a las redes neuronales {.center}\n::: incremental \n_live coding_ en Google Colab para entender las redes neuronales.\n:::\n\n\n## Paper de Rosenblatt\n\n![](img/summary_perceptron.png){ .lightbox}\n\n\n\n## Detalle ampliado\n\n![](img/language_translation.png){ .lightbox }\n\n## Invierno de la IA (1974--1980)\n\n\n<br>\n<br>\n\n\n  El **informe Lighthill** de Sir James Lighthill (enero de 1973), encargado por el Consejo de Investigación de Ciencias del Reino Unido, concluyó que los avances reales de la IA estaban muy por debajo de lo prometido y recomendó retirar la mayor parte de los fondos estatales a proyectos en este campo.\n\n\n## ¿Qué es un perceptrón\n\n<br>\n\n- Unidad de procesamiento inspirada en la **neurona biológica**.  \n- Clasificador binario: decide si una entrada pertenece a una clase u otra.  \n- Propuesto por **Frank Rosenblatt** en 1957.\n\n\n## Esquema del perceptrón\n\n<br>\n<br>\n\n![](img/perceptron_scheme.png){ .lightbox}\n\n\n## Perceptrón\n\n<br>\n\n$z = \\mathbf{w}^\\top \\mathbf{x} + b$\n\n<br>\n\n$h(z) =\n\\begin{cases}\n0, & z < 0,\\\\\n1, & z \\ge 0,\n\\end{cases}$\n\n<br>\n\n$y = h\\bigl(\\mathbf{w}^\\top \\mathbf{x} + b\\bigr)$\n<!-- $y = f_{w,b}(\\mathbf{x}) = h\\bigl(\\mathbf{w}^\\top \\mathbf{x} + b\\bigr)$ -->\n\n<!-- ## Error y actualización -->\n\n$\\text{error}=Y−y$ \n\n$\\Delta w_i = \\mathrm{LR}\\,\\bigl(Y - y\\bigr)\\,x_i$\n\n\n\n## Manual de uso de un perceptrón\n\n\n1. **Inicializar**  \n   <!-- - Poner todos los pesos en cero.  \n   - Poner el sesgo (bias) en cero. -->\n\n2. **Iterar por épocas**  \n   <!-- - Repetir el ciclo de aprendizaje un número fijo de veces. -->\n\n3. **Para cada ejemplo de entrenamiento**  \n   1. **Calcular la salida del perceptrón**  \n      <!-- - Multiplicar las entradas por sus pesos, sumar el sesgo y aplicar la función de activación (paso unitario).   -->\n   2. **Calcular el error**  \n      <!-- - Restar la salida obtenida de la etiqueta correcta.   -->\n   3. **Actualizar los pesos y sesgo**  \n      <!-- - Ajustar cada peso proporcional al error, a la entrada correspondiente y a la tasa de aprendizaje.   -->\n   <!-- 4. **Actualizar el sesgo**   -->\n      <!-- - Ajustar el sesgo proporcional al error y a la tasa de aprendizaje. -->\n\n4. **Devolver pesos y el sesgo ajustados**\n\n## Puerta lógica AND\n\n\n:::: {.columns}\n\n:::{.column width=\"40%\" .right }\n\n<table>\n  <thead style=\"background-color: #f0f0f0;\">\n    <tr>\n      <th style=\"padding: 8px 12px; text-align: center;\">A</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">B</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">A & B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #d4edda; padding: 8px 12px; text-align: center;\">1</td>\n    </tr>\n  </tbody>\n</table>\n\n:::\n\n:::{.column width=\"60%\"}\n```python \n# Entradas\nx = np.array([\n    [0, 0],\n    [0, 1],\n    [1, 0],\n    [1, 1]\n])\n\n# Salidas deseadas\nY = np.array([0, 0, 0, 1])\n\n# Pesos iniciales\nw = np.array([0,0])\n\n# Sesgo inicial\nb = 0\n``` \n:::\n\n::::\n\n\n## Puerta lógica XOR\n\n:::: {.columns}\n\n:::{.column width=\"40%\" .right}\n\n<table>\n  <thead style=\"background-color: #f0f0f0;\">\n    <tr>\n      <th style=\"padding: 8px 12px; text-align: center;\">A</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">B</th>\n      <th style=\"padding: 8px 12px; text-align: center;\">A ⊕ B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #d4edda; padding: 8px 12px; text-align: center;\">1</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">0</td>\n      <td style=\"background-color: #d4edda; padding: 8px 12px; text-align: center;\">1</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"padding: 8px 12px; text-align: center;\">1</td>\n      <td style=\"background-color: #f8d7da; padding: 8px 12px; text-align: center;\">0</td>\n    </tr>\n  </tbody>\n</table>\n\n:::\n\n:::{.column width=\"60%\"}\n\n  ```python\n  # Entradas\n  x = np.array([\n      [0, 0],\n      [0, 1],\n      [1, 0],\n      [1, 1]\n  ])\n\n  # Salidas deseadas para XOR\n  Y = np.array([0, 1, 1, 0])\n\n# Pesos iniciales\nw = np.array([0,0])\n\n# Sesgo inicial\nb = 0\n```\n\n:::\n\n::::\n\n## AND: Perceptrón en Google Colab\n\n[![](img/google_colab_AND.png)](https://colab.research.google.com/drive/1OMee_vTQXbdsXTrN6syQydwA8k_ccVp_?usp=sharing)\n\n\n\n## XOR: Perceptrón en Google Colab\n\n[![](img/google_colab_XOR.png)](https://colab.research.google.com/drive/10nrTgGWWoMYsv_Os3cbFlF0eAI1Spx1p?usp=sharing)\n\n\n\n## AND y XOR\n\n![](img/error_XOR.png){.lightbox} \n\n## AND y XOR {.center}\n\n![](img/and_or_xor.png){.lightbox}\n\n\n## Backpropagation y Redes Neuronales\n\n| Año      | Investigador              | “Nombre” de la contribución   |\n| -------- | ------------------------- | ---------------------------   |\n| **1970** | Seppo Linnainmaa          | *Reverse-mode AD*             |\n| **1974** | Paul Werbos               | *Back-prop en redes*          |\n| **1982** | John Hopfield             | *Interés en redes neuronales* |\n| **1986** | Rumelhart-Hinton-Williams | *Back-prop popularizado*      |\n\n\n## Backpropagation + Multicapa\n\n| Paso               | Perceptrón simple            | Multicapa (+ back-prop)                     |\n| ------------------ | ---------------------------- | ------------------------------------------- |\n| Activación         | Escalón (`h`) – no derivable | Sigmoide – derivable                        |\n| Capas              | 1 (entrada → salida)         | 2 (entrada → oculta → salida)               |\n| Aprendizaje        | Regla de perceptrón          | Gradiente descendente con retro-propagación |\n| Puede aprender XOR | ❌                            | ✅                                           |\n\n## Multicapas {.center}\n\n![](img/multicapas.png)\n\n## Back-propagation: cómo aprende una red\n\n\n* Calcula el **error** en la salida.\n* Propaga ese error **hacia atrás** usando la regla de la cadena para obtener la pendiente (gradiente) de cada peso.\n* Combina los gradientes con **descenso del gradiente** (u otro optimizador) para actualizar los parámetros.\n* Permite entrenar cualquier grafo computacional compuesto de operaciones derivables.\n\n\n\n\n## XOR: Red neuronal en Google Colab\n\n[![](img/red_xor.png)](https://colab.research.google.com/drive/11L2vVBkQ65aNBMT-lrMGZjp5Q9606Nn9?usp=sharing)\n\n\n\n## Playground TensorFlow {.center}\n\n![https://playground.tensorflow.org/](https://playground.tensorflow.org/)\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","incremental":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.7.28","auto-stretch":true,"title":"Del perceptrón a las redes neuronales","author":"Guillermo Barrios","date":"2025-05-24","theme":"simple","logo":"img/logo.png","slideNumber":true,"transition":"fade"}}},"projectFormats":["html"]}